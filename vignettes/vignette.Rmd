---
title: "timeOmics"
author: 
- name:  "Antoine Bodein"
  affiliation: "CHU de Québec Research Center, Université Laval, Molecular Medicine department, Québec, QC, Canada"
  email: "antoine.bodein.1@ulaval.ca"
package: timeOmics
output: 
  BiocStyle::html_document
vignette: >
  %\VignetteIndexEntry{timeOmics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

# Introduction

***timeOmics*** is a generic data-driven framework to integrate multi-Omics longitudinal data (**A.**) measured on the same biological samples and select key temporal features with strong associations within the same sample group.

The main steps of ***timeOmics*** are:

* a pre-procesing step (**B.**) to normalize and filter low-expressed and not time-varying features,
* a modelling step (**C.**) to capture inter-individual variability in biological/technical replicates.
* a clustering step (**D.**) to group features with the same expression profile over time. We can also use a feature selection step to identify a signature per cluster.
* a post-hoc validation step (**E.**) to ensure clustering quality.

We present this framework on both single-Omic and multi-Omics situations.

![Framework Overview](./img/method_overview.png)

For more details please check:  
*Bodein A, Chapleur O, Droit A and Lê Cao K-A (2019) A Generic Multivariate Framework for the Integration of Microbiome Longitudinal Studies With Other Data Types. Front. Genet. 10:963. doi: 10.3389/fgene.2019.00963*

# Start

## Installation

```{r, echo =  FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = TRUE,
                      fig.align = "center",
                      warning = FALSE,
                      message = FALSE)
```


```r
install.packages("devtools")
# then load
library(devtools)
install_github("abodein/timeOmics_BioC")
```

## Load the package

```{r, message=FALSE, warning=FALSE}
library(timeOmics)
```

# Data preprocessing

Each analysis starts with a pre-processing step. 
In longitudinal multi-omics analysis we have a 2-step pre-processing.

1. Omic-specific pre-processing depending on the used technology to collect Omics data. 
(log, scale, rle, low count removal, ...)
2. Time-specific pre-processing. Here, we are interested in keeping only features that vary over time.

## Required data


```{r}
data("timeOmics.simdata")
raw.data <- timeOmics.simdata$rawdata
```




# Time Modelling

We rely on a *Linear Mixed Model Splines* framework (package `LMMS`) to model features expression as a function of time.

LMMS framework tests 4 different models and assigns one of the following models to each feature:

* 0 = linear model, 
* 1 = linear mixed effect model spline (LMMS) with defined basis, 
* 2 = LMMS taking subject-specific random intercept, 
* 3 = LMMS with subject specific intercept and slope.

LMMS will take into account all inter-individual variability and summarize each feature into a unique time profile.

## Required data

Let's run `lmms` on simulated dataset.


```{r}
library(lmms)
library(tidyverse) # this one will be useful for the rest

data("timeOmics.simdata")
sim.data <- timeOmics.simdata$sim
sim.data[1:15,1:6]
```

LMMS requires a dataframe with features in columns and samples in rows.
Here my rownames are represented like this: **ID_Time**

For more information about LMMS modelling parameters, please check (link lmms)

```{r}
time <- rownames(sim.data) %>% str_remove("._") %>% as.numeric()
LMMS.output <- lmms::lmmSpline(data = sim.data, time = time,
                        sampleID = rownames(sim.data), deri = FALSE,
                        basis = "p-spline", numCores = 4, timePredict = 1:9, 
                        keepModels = TRUE)
data <- t(LMMS.output@predSpline)
```

## LMMS output 

LMMS reduces the dimension of the data.
The produced table contains features in columns and now, times in lines.

Let's plot the modelled profiles.

```{r}
# gather data
data.gathered <- data %>% as.data.frame() %>% 
  rownames_to_column("time") %>%
  mutate(time = as.numeric(time)) %>%
  gather(feature, value, -time)

# plot profiles
ggplot(data.gathered, aes(x = time, y = value, color = feature)) + geom_line() +
  theme_bw() + ggtitle("LMMS profiles") + ylab("Features expression") +
  xlab("Time")
```

## Profile filtering

Straight line modelling can occur when the inter-individual variation is too high.
To remove the noisy profiles, we first use the Breusch-Pagan test, which tests the homo-sedasticity of the residues.
We then add a filter on the mean squared error to reduce the dispersion of the residues around the line.

```{r}
#wrapper.filter.splines
```

# (s)PCA longitudinal clustering

From the modelled data, we use a PCA to cluster features with a samilar expression profile over time.

PCA is un unsupervised reduction dimension technique which use uncorrelated 
intrumental variable (a.k.a principal components) to summarize as much information 
(*variance*) as possible from the data.

```{r}
data("timeOmics.simdata")
data <- timeOmics.simdata$modelled
```

## clustering

Text about clustering and how it is done in our case. 

* loading scores
* component
* contribution
* silhouette coefficient

Optimize the number of component
First, run a PCA and optimise 

```{r}
# run pca
pca.res <- pca(X = data, ncomp = 5, scale=F)

pca.ncomp <- getNcomp(pca.res, max.ncomp = 5, X = data)
plot(pca.ncomp)
```

Thanks to the previous plot, highest silhouette coefficient is achieved when `ncomp = 2`.

```{r}
pca.res <- pca(X = data, ncomp = 2,scale = F, center=F)
```

All information about the cluster is displayed here.

```{r}
# extract cluster
pca.cluster <- getCluster(pca.res)
head(pca.cluster)
```

### Plot PCA clusters

```{r}
plotVar(pca.res)
plotLong(pca.res, scale = F, center = F)
```


## sparse PCA

The previous clustering used all features. Sometimes we are interested in a cluster signature.
We then use the sparse PCA to extract this key signature.

To find the right number of features to keep per component and thus per cluster, we evaluate the silhouette for a list of selected features on each component.

We do not recommend using a parameter that is too small since it will tend to pull the silhouette coefficient upwards and bias the interpretation regarding the number of features to be selected.

We will then follow the evolution of the silhouette coefficient of each cluster (component and contribution). 
The main idea here is to detect a significant decrease in the evolution of the silhouette for each component.
In other words, if we add 1 OTU, will the cluster be distorted?

```{r}
data <- timeOmics.simdata$modelled
tune.spca.res <- tuneCluster.spca(X = data, ncomp = 2, test.keepX = c(2:10))
plot(tune.spca.res)
```



```{r}
spca.res <- spca(X = data, ncomp = 2, keepX = c(8,7), scale = FALSE)
plotLong(spca.res)
```


# (s)PLS longitudinal clustering

```{r}
X <- data
Y <- data[,sample(1:20, size = 8)]
colnames(Y) <- paste0("Y", 1:ncol(Y))

pls.res <- pls(X,Y, ncomp = 2, scale = TRUE)

getCluster(pls.res) %>% head

plotLong(pls.res)

tune.spls <- tuneCluster.spls(X, Y, ncomp = 2, test.keepX = c(5,10,15,20), test.keepY <- c(2,4,6))
```

need a graph for keepX/keepY

# Multi-block (s)PLS longitudinal clustering

```{r}
X <- data
Y <- data[,sample(1:20, size = 8)]
colnames(Y) <- paste0("Y", 1:ncol(Y))

Z <- data[,sample(1:20, size = 12)]
colnames(Z) <- paste0("Z", 1:ncol(Z))

block.pls.res <- block.pls(X = list("X"=X,"Z"=Z), Y, ncomp = 2, scale = TRUE)

block.pls.cluster <- getCluster(block.pls.res)
head(block.pls.cluster)

plotLong(block.pls.res)
```


# Post-hoc evaluation

We compute the proportionality distance between features of the same cluster.
By keeping the features close to each other, it guarantees the authenticity of the interactions.
We also use a Wilcoxon U-test to compare the within cluster median compared to the entire background set.


```{r, eval =T}
# example fro multiblock analysis
res <- timeOmics::proportionality(block.pls.res)
# distance between pairs of features
head(res$propr.distance)[1:6]
# u-test pvalue by clusters
pval.propr <- res$pvalue 
knitr::kable(pval.propr)
plot(res)
```
